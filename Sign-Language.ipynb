{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SURESH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\SURESH\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\SURESH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "import tensorflow as tf \n",
    "from keras.models import load_model\n",
    "\n",
    "from wordsegment import load,segment\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "img_width = 1280\n",
    "img_height = 720\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, img_width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, img_height)\n",
    "\n",
    "def image_resize(image, height = 45, inter = cv2.INTER_AREA):\n",
    "    resized = cv2.resize(image, (height,height), interpolation = inter)\n",
    "    return resized\n",
    "\n",
    "model = load_model('trained.h5')\n",
    "\n",
    "encoding_chart = pd.read_csv('label_encoded.csv')\n",
    "encoding_values = encoding_chart['Encoded'].values\n",
    "encoding_labels = encoding_chart['Label'].values\n",
    "int_to_label = dict(zip(encoding_values,encoding_labels))\n",
    "\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "\n",
    "history = list()\n",
    "counts = dict()\n",
    "history_length = 15\n",
    "threshold = 0.9\n",
    "\n",
    "start = 200\n",
    "end = 500\n",
    "alpha = 0.4\n",
    "\n",
    "sentence_raw = list()\n",
    "\n",
    "color = (59, 185, 246)\n",
    "\n",
    "load()\n",
    "\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.flip(img,1)\n",
    "    alpha_layer = img.copy()\n",
    "    source = img.copy()\n",
    "\n",
    "    crop_img = source[start:end, start:end]\n",
    "    cv2.circle(alpha_layer, (int((start+end)/2),int((start+end)/2)), int((end - start)/2), color ,-1)\n",
    "    cv2.addWeighted(alpha_layer, alpha, img, 1 - alpha,0, img)\n",
    "\n",
    "    grey = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "    resized = image_resize(crop_img)\n",
    "    predicted = model.predict(np.array([resized]))\n",
    "\n",
    "    predicted_char = int_to_label[np.argmax(predicted)]\n",
    "    #print(predicted_char)\n",
    "    text_file = open(\"Output.txt\", \"w\")\n",
    "    text_file.write(\"Purchase Amount: %s\" %  predicted_char)\n",
    "    text_file.close()\n",
    "    \n",
    "    if(len(history)>=history_length):\n",
    "        keys = list(counts.keys())\n",
    "        values = list(counts.values())\n",
    "        arg = np.argmax(values)\n",
    "        if(values[arg]>threshold*history_length):\n",
    "            sentence_raw.append(keys[arg])\n",
    "        counts.clear()\n",
    "        history.clear()\n",
    "    if(predicted_char != 'None'):\n",
    "        history.append(predicted_char)\n",
    "        if(predicted_char in counts):\n",
    "            counts[predicted_char]+=1\n",
    "        else:\n",
    "            counts[predicted_char]=1\n",
    "        textsize = cv2.getTextSize(predicted_char, font, 6,7)[0]\n",
    "        textX = int(start + ((end - start) - textsize[0])/2)\n",
    "        textY = int(end - ((end - start) - textsize[1])/2)\n",
    "        cv2.putText(img, predicted_char, (textX,textY),font,6,color,7)\n",
    "\n",
    "    scribble = \"\".join(sentence_raw)\n",
    "    sentence = \" \".join(segment(scribble))\n",
    "    sentencesize = cv2.getTextSize(sentence, font, 1,2)[0]\n",
    "\n",
    "    if(len(sentence)>0):\n",
    "        cv2.rectangle(img,(int((img_width - sentencesize[0])/2) - 20,img_height - 140),(int((img_width - sentencesize[0])/2 + sentencesize[0] + 20),img_height - 100 + sentencesize[1]),(0,0,0),-1)\n",
    "    if(len(sentence)>30):\n",
    "        sentence_raw = list(segment(scribble)[-1])\n",
    "\n",
    "    cv2.putText(img, sentence, (int((img_width - sentencesize[0])/2),img_height - 100),font,1,(255,255,255),2)\n",
    "\n",
    "    cv2.imshow('WebCam', img)\n",
    "    k = cv2.waitKey(10)\n",
    "    if k == ord('x') or k == ord('X'):\n",
    "        sentence_raw.clear()\n",
    "    if k == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
